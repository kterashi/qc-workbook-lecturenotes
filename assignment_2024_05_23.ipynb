{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【課題】高エネルギー実験で生成された荷電粒子の飛跡を見つける"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "必要なライブラリを最初にインポートします。\n",
    "\n",
    "### 最初に注意\n",
    "**すぐ下のセルを実行すると、「セッションを再起動する」というポップアップウインドウが出てくる場合があります。これは一部のパッケージが古くて更新されていないからですが、そのまま「セッションを再起動する」をクリックして、再度同じセルを実行してください。2度目は大丈夫のはずです。それ以降のセルは普通に実行してください。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import shutil\n",
    "import tarfile\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/gdrive')\n",
    "shutil.copy('/content/gdrive/MyDrive/qcintro.tar.gz', '.')\n",
    "with tarfile.open('qcintro.tar.gz', 'r:gz') as tar:\n",
    "    tar.extractall(path='/root/.local')\n",
    "\n",
    "sys.path.append('/root/.local/lib/python3.10/site-packages')\n",
    "\n",
    "!git clone -b branch-2024 https://github.com/kterashi/qc-workbook-lecturenotes\n",
    "!cp -r qc-workbook-lecturenotes/qc_workbook /root/.local/lib/python3.10/site-packages/\n",
    "!cp -r qc-workbook-lecturenotes/hepqpr /root/.local/lib/python3.10/site-packages/\n",
    "\n",
    "%pip install qiskit-optimization\n",
    "%pip install 'git+https://github.com/LAL/trackml-library.git'\n",
    "%pip install dwave-qbsolv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Tested with python 3.10.11, qiskit 0.42.1, numpy 1.23.5, scipy 1.9.3\n",
    "import pprint\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.circuit.library import TwoLocal\n",
    "from qiskit.primitives import BackendEstimator\n",
    "from qiskit_algorithms.minimum_eigensolvers import VQE, NumPyMinimumEigensolver\n",
    "from qiskit_algorithms.optimizers import SPSA, COBYLA\n",
    "from qiskit_algorithms.gradients import ParamShiftEstimatorGradient\n",
    "from qiskit.quantum_info import SparsePauliOp, Statevector\n",
    "from qiskit_optimization.applications import OptimizationApplication\n",
    "from qiskit_aer import AerSimulator"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## データセットの生成\n",
    "\n",
    "最初に、この課題で使う検出器データを作ります。このデータはシミュレーションで作成したものですが、実際の検出器で測定した加速器衝突実験データを模したものです。\n",
    "\n",
    "乱数のシードを固定して、同じデータを作るようにします。この課題では`random_seed=10111`で固定してください。`density`は再構成に使う1事象あたりの飛跡の密度を表しますが、ここも0.15%で固定しておきます。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from hepqpr.qallse.dsmaker import create_dataset\n",
    "\n",
    "density = 0.0015\n",
    "\n",
    "output_path = os.getcwd()+'/ds'\n",
    "prefix = 'ds'+str(density)\n",
    "\n",
    "metadata, path = create_dataset(\n",
    "    density=density,\n",
    "    output_path=output_path,\n",
    "    prefix=prefix,\n",
    "    random_seed=10111,\n",
    "      #10111 - 17 triplets (1 track)\n",
    "      # 1005 - 29 triplets (2 tracks with fake)\n",
    "      # 1029 - 30 triplets (3 tracks, no fake)\n",
    "    gen_doublets=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "下のセルを実行すると、作成したデータを整理し、データに含まれるセグメント（triplet）の数などの情報をプリントアウトします。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from hepqpr.qallse import *\n",
    "\n",
    "# ==== BUILD CONFIG\n",
    "loglevel = logging.INFO\n",
    "\n",
    "input_path = os.getcwd()+'/ds/'+prefix+'/event000001000-hits.csv'\n",
    "output_path = os.getcwd()+'/ds/'+prefix+'/'\n",
    "\n",
    "model_class = QallseD0  # model class to use\n",
    "extra_config = dict()  # model config\n",
    "\n",
    "dump_config = dict(\n",
    "    output_path = os.getcwd()+'/ds/'+prefix+'/',\n",
    "    prefix=prefix+'_',\n",
    "    xplets_kwargs=dict(format='json', indent=3), # use json (vs \"pickle\") and indent the output\n",
    "    qubo_kwargs=dict(w_marker=None, c_marker=None) # save the real coefficients VS generic placeholders\n",
    ")\n",
    "\n",
    "# ==== configure logging\n",
    "logging.basicConfig(\n",
    "    stream=sys.stderr,\n",
    "    format=\"%(asctime)s.%(msecs)03d [%(name)-15s %(levelname)-5s] %(message)s\",\n",
    "    datefmt='%Y-%m-%dT%H:%M:%S')\n",
    "\n",
    "logging.getLogger('hepqpr').setLevel(loglevel)\n",
    "\n",
    "# ==== build model\n",
    "# load data\n",
    "dw = DataWrapper.from_path(input_path)\n",
    "doublets = pd.read_csv(input_path.replace('-hits.csv', '-doublets.csv'))\n",
    "\n",
    "# build model\n",
    "model = model_class(dw, **extra_config)\n",
    "model.build_model(doublets)\n",
    "\n",
    "# dump model to a file\n",
    "dumper.dump_model(model, **dump_config)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "次のセルでデータからQUBOを作成します。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pickle\n",
    "from os.path import join as path_join\n",
    "\n",
    "from hepqpr.qallse.other.stdout_redirect import capture_stdout\n",
    "from hepqpr.qallse.other.dw_timing_recorder import solver_with_timing, TimingRecord\n",
    "from hepqpr.qallse.plotting import *\n",
    "\n",
    "# ==== RUN CONFIG\n",
    "nreads = 10\n",
    "nseed = 1000000\n",
    "\n",
    "loglevel = logging.INFO\n",
    "\n",
    "input_path = os.getcwd()+'/ds/'+prefix+'/event000001000-hits.csv'\n",
    "qubo_path = os.getcwd()+'/ds/'+prefix+'/'\n",
    "\n",
    "# ==== configure logging\n",
    "logging.basicConfig(\n",
    "    stream=sys.stdout,\n",
    "    format=\"%(asctime)s.%(msecs)03d [%(name)-15s %(levelname)-5s] %(message)s\",\n",
    "    datefmt='%Y-%m-%dT%H:%M:%S')\n",
    "\n",
    "logging.getLogger('hepqpr').setLevel(loglevel)\n",
    "\n",
    "# ==== build model\n",
    "# load data\n",
    "dw = DataWrapper.from_path(input_path)\n",
    "pickle_file = prefix+'_qubo.pickle'\n",
    "with open(path_join(qubo_path, pickle_file), 'rb') as f:\n",
    "    Q = pickle.load(f)\n",
    "#print(Q)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ハミルトニアンの構成とVQEの実行"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### QUBO\n",
    "\n",
    "ワークブックにあるセットアップで、各セグメントを粒子飛跡の一部として採用するかフェイクとして棄却するかを考えます。具体的には、$N$個のセグメントのうち$i$番目の採用・棄却を二値変数$T_i$の値1と0に対応させ、目的関数\n",
    "\n",
    "$$\n",
    "O(b, T) = \\sum_{i=1}^N a_{i} T_i + \\sum_{i=1}^N \\sum_{j<i}^N b_{ij} T_i T_j\n",
    "$$\n",
    "\n",
    "を最小化する$\\{T_i\\}$を求めます。ここで$a_i$は上で決めたセグメント$i$のスコア、$b_{ij}$はセグメント$i$と$j$のペアのスコアです。$a_i$の値が小さい（検出器中心を向いている）、かつ$b_{ij}$の値が小さい（正しい飛跡と無矛盾な）ペアを組んでいるセグメントを採用し、そうでないものを棄却するほど、$O$の値は小さくなります。採用すべきセグメントが決まれば、それに基づいてすべての粒子飛跡を再構成できるので、この最小化問題を解くことがトラッキングに対応します。\n",
    "\n",
    "それでは、まずスコア$a_{i}$と$b_{ij}$を作成したQUBOから読み出します。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# スコアの読み込み\n",
    "n_max = 100\n",
    "\n",
    "nvar = 0\n",
    "key_i = []\n",
    "a_score = np.zeros(n_max)\n",
    "for (k1, k2), v in Q.items():\n",
    "    if k1 == k2:\n",
    "        a_score[nvar] = v\n",
    "        key_i.append(k1)\n",
    "        nvar += 1\n",
    "a_score = a_score[:nvar]\n",
    "\n",
    "b_score = np.zeros((n_max,n_max))\n",
    "for (k1, k2), v in Q.items():\n",
    "    if k1 != k2:\n",
    "        for i in range(nvar):\n",
    "            for j in range(nvar):\n",
    "                if k1 == key_i[i] and k2 == key_i[j]:\n",
    "                    if i < j:\n",
    "                        b_score[j][i] = v\n",
    "                    else:\n",
    "                        b_score[i][j] = v\n",
    "\n",
    "b_score = b_score[:nvar,:nvar]\n",
    "\n",
    "print(f'Number of segments: {a_score.shape[0]}')\n",
    "# 最初の5x5をプリント\n",
    "print(a_score[:5])\n",
    "print(b_score[:5, :5])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ising形式\n",
    "\n",
    "QUBOの目的関数はまだハミルトニアンの形になっていない（エルミート演算子でない）ので、VQEを使ってこの問題を解くにはさらに問題を変形する必要があります。ここで$T_i$が$\\{0, 1\\}$のバイナリー値を持つことに着目すると、\n",
    "\n",
    "$$\n",
    "T_i = \\frac{1}{2} (1 - s_i)\n",
    "$$\n",
    "\n",
    "で値$\\{+1, -1\\}$を持つ変数$s_i$を定義できます。次に、$\\{+1, -1\\}$はパウリ演算子の固有値でもあるため、$s_i$を量子ビット$i$にかかるパウリ$Z$演算子で置き換えると、$N$量子ビット系の各計算基底がセグメントの採用・棄却をエンコードする固有状態となるような目的ハミルトニアン\n",
    "\n",
    "$$\n",
    "H(h, J, s) = \\sum_{i=1}^N h_i Z_i + \\sum_{i=1}^N \\sum_{j<i}^N J_{ij} Z_i Z_j + \\text{(constant)}\n",
    "$$\n",
    "\n",
    "が得られます。これは物理を始め自然科学の様々な場面で登場するIsing模型のハミルトニアンと同じ形になっています。右辺の$constant$はハミルトニアンの定数項で、変分法において意味を持たないので以降は無視します。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 問題1\n",
    "\n",
    "以下のセルで、上の処方に従ってIsingハミルトニアンの係数$h_i$と$J_{ij}$を計算してください。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_qubits = nvar\n",
    "\n",
    "coeff_h = np.zeros(num_qubits)\n",
    "coeff_J = np.zeros((num_qubits, num_qubits))\n",
    "\n",
    "##################\n",
    "### EDIT BELOW ###\n",
    "##################\n",
    "\n",
    "# coeff_hとcoeff_Jをb_ijから計算してください\n",
    "\n",
    "##################\n",
    "### EDIT ABOVE ###\n",
    "##################"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "次に、この係数をもとに、VQEに渡すハミルトニアンをSparsePauliOpとして定義します。{ref}`vqe_imp`ではSparsePauliOpは単一のパウリ積$ZXY$を表現するのに使いましたが、実はパウリ積の和も同じクラスを使って表現できます。例えば\n",
    "\n",
    "$$\n",
    "H = 0.2 IIZ + 0.3 ZZI + 0.1 ZIZ\n",
    "$$\n",
    "\n",
    "は\n",
    "\n",
    "```python\n",
    "H = SparsePauliOp(['IIZ', 'ZZI', 'ZIZ'], coeffs=[0.2, 0.3, 0.1])\n",
    "```\n",
    "\n",
    "となります。このとき、通常のQiskitの約束に従って、量子ビットの順番が右から左（一番右が第0量子ビットにかかる演算子）であることに注意してください。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 問題2\n",
    "\n",
    "以下のセルで、 係数が0でないパウリ積をすべて拾い出し、対応する係数の配列を作成してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##################\n",
    "### EDIT BELOW ###\n",
    "##################\n",
    "\n",
    "# 係数が0でないパウリ積をすべて拾い出し、対応する係数の配列を作成してください\n",
    "\n",
    "pauli_products = []\n",
    "coeffs = []\n",
    "\n",
    "##################\n",
    "### EDIT ABOVE ###\n",
    "##################\n",
    "\n",
    "hamiltonian = SparsePauliOp(pauli_products, coeffs=coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 厳密対角化で基底エネルギーを求める\n",
    "\n",
    "乱数のシードを`random_seed=10111`で固定して、飛跡の密度も`density=0.0015`に固定した場合、厳密対角化の答えは`-15.063505`になるはずです。答えの確認に使ってください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "raises-exception",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "# ハミルトニアン行列を対角化して、エネルギーの最小固有値と固有ベクトルを求める\n",
    "ee = NumPyMinimumEigensolver()\n",
    "result_diag = ee.compute_minimum_eigenvalue(hamiltonian)\n",
    "\n",
    "# 最小エネルギーに対応する量子ビットの組み合わせを表示\n",
    "print(f'Minimum eigenvalue (diagonalization): {result_diag.eigenvalue.real}')\n",
    "# 解状態を計算基底で展開し、最も確率の高い計算基底を選ぶ\n",
    "optimal_segments_diag = OptimizationApplication.sample_most_likely(result_diag.eigenstate)\n",
    "print(f'Optimal segments (diagonalization): {optimal_segments_diag}')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### VQEで基底エネルギーを求める\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "backend = AerSimulator()\n",
    "# Estimatorインスタンスを作る\n",
    "estimator = BackendEstimator(backend)\n",
    "\n",
    "# VQE用の変分フォームを定義。ここではTwoLocalという組み込み関数を使う\n",
    "ansatz = TwoLocal(num_qubits, 'ry', 'cz', 'linear', reps=1)\n",
    "\n",
    "# オプティマイザーを選ぶ\n",
    "optimizer_name = 'SPSA'\n",
    "\n",
    "if optimizer_name == 'SPSA':\n",
    "    optimizer = SPSA(maxiter=300)\n",
    "    grad = ParamShiftEstimatorGradient(estimator)\n",
    "\n",
    "elif optimizer_name == 'COBYLA':\n",
    "    optimizer = COBYLA(maxiter=500)\n",
    "    grad = None\n",
    "\n",
    "# パラメータの初期値をランダムに設定\n",
    "rng = np.random.default_rng()\n",
    "init = rng.uniform(0., 2. * np.pi, size=len(ansatz.parameters))\n",
    "\n",
    "# VQEオブジェクトを作り、基底状態を探索する\n",
    "vqe = VQE(estimator, ansatz, optimizer, gradient=grad, initial_point=init)\n",
    "result_vqe = vqe.compute_minimum_eigenvalue(hamiltonian)\n",
    "\n",
    "# 最適解のパラメータ値をansatzに代入し、状態ベクトルを計算する\n",
    "optimal_state = Statevector(ansatz.assign_parameters(result_vqe.optimal_parameters))\n",
    "\n",
    "# 最小エネルギーに対応する量子ビットの組み合わせを表示\n",
    "print(f'Minimum eigenvalue (VQE): {result_vqe.eigenvalue.real}')\n",
    "optimal_segments_vqe = OptimizationApplication.sample_most_likely(optimal_state)\n",
    "print(f'Optimal segments (VQE): {optimal_segments_vqe}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 結果を可視化する\n",
    "\n",
    "Trackingがうまく行っても、この答えだと0と1が並んでいるだけで面白くないですよね。正しく飛跡が見つかったかどうか目で確認するため、以下のコードを走らせてみましょう。厳密対角化の結果を図示する時は`type = \"diag\"`、VQEの結果を図示する時は`type = \"vqe\"`としてください。\n",
    "\n",
    "正しい計算ができていれば、いくつかの情報とともに\"tracks found: 1\"という結果が出て、その時の飛跡の図が作られます。この図はQUBOを定義する時に使った検出器のヒット位置をビーム軸に垂直な平面に投影したものです。再構成が成功していれば、ヒットが繋がって飛跡として再構成されていることが見て取れるはずです。緑の線が実際に見つかった飛跡です。\n",
    "\n",
    "この図のhtmlファイルは、ウィンドウの左端にあるフォルダアイコン（鍵マークの下）をクリックし、出てくるサブウィンドウの中の`plot-ising_[type]_found_tracks.html`です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "raises-exception",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "from hepqpr.qallse import DataWrapper, Qallse, TrackRecreaterD\n",
    "from hepqpr.qallse.plotting import iplot_results, iplot_results_tracks\n",
    "from hepqpr.qallse.utils import diff_rows\n",
    "\n",
    "# どちらの結果をプロットするか指定する\n",
    "#   diag = 厳密対角化の結果\n",
    "#   vqe = VQEの結果\n",
    "type = \"diag\"\n",
    "#type = \"vqe\"\n",
    "\n",
    "if type == \"diag\":\n",
    "    optimal_segments = optimal_segments_diag\n",
    "elif type == \"vqe\":\n",
    "    optimal_segments = optimal_segments_vqe\n",
    "\n",
    "samples = dict(zip(key_i, optimal_segments))\n",
    "\n",
    "# 結果を取得\n",
    "all_doublets = Qallse.process_sample(samples)\n",
    "\n",
    "final_tracks, final_doublets = TrackRecreaterD().process_results(all_doublets)\n",
    "\n",
    "#dw = DataWrapper.from_path('data/event000001000-hits.csv')\n",
    "input_path = os.getcwd()+'/ds/'+prefix+'/event000001000-hits.csv'\n",
    "dw = DataWrapper.from_path(input_path)\n",
    "\n",
    "p, r, ms = dw.compute_score(final_doublets)\n",
    "trackml_score = dw.compute_trackml_score(final_tracks)\n",
    "\n",
    "print(f'SCORE  -- precision (%): {p * 100}, recall (%): {r * 100}, missing: {len(ms)}')\n",
    "print(f'          tracks found: {len(final_tracks)}, trackml score (%): {trackml_score * 100}')\n",
    "\n",
    "dims = ['x', 'y']\n",
    "_, missings, _ = diff_rows(final_doublets, dw.get_real_doublets())\n",
    "dout = 'plot-ising_'+type+'_found_tracks.html'\n",
    "iplot_results(dw, final_doublets, missings, dims=dims, filename=dout)\n",
    "\n",
    "from IPython.display import HTML\n",
    "HTML(dout)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### おまけ\n",
    "\n",
    "この課題では、少数の量子ビットで実行できるように飛跡は一本だけにしています。上で指定した乱数のシードを`1029`として実行すると3本の飛跡を持つデータを作成するので、興味のある人は遊んでみてください。\n",
    "\n",
    "色々シードを変えてデータを作って遊んでもらって良いですが、セグメントの数が多すぎるとメモリ不足を起こしてセッションがクラッシュします。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**提出するもの**\n",
    "- ハミルトニアンを実装する部分のコード（問題1と問題2）"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
